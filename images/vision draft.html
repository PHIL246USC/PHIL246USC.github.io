


---
template: inverse

# The anatomy of vision

---
class: center, middle

.image-100[![](images/2b-anatomy-pathways.jpeg)] 

???

The cornea protects the surface of the eye, the pupil is where light waves enter; its size can change as a function of light levels and other internal processes. Its size is controlled by the iris. Light passes through the lens that aids in focusing light; in normal-sighted individuals, it focuses images perfectly on the fovea which is part of the retina. 

This is the beginning of the information-theoretic action. 


Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/


---
class: center, middle

.image-100[![](images/2b-anatomy-photoreceptors.jpeg)]

???

"The fovea contains densely packed specialized photoreceptor cells, known as cones", which work best in bright light, and "rods are located throughout the remainder of the retina". Rods are specialized for low light conditions and for movement in the visual periphery. 

Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/



---
class: center, middle

.image-100[![](images/2b-anatomy-eye.jpeg)]

???

"Rods and cones are connected... to retinal ganglion cells. Axons from the retinal ganglion converge and exit through the back of the eye to form the optic nerve. The optic nerve carries visual information from the retina to the brain." ... "The optic nerve from each eye merges ..at  apoint called the optic chiams ... [and at that point] informtion from the right visual field (which comes from both eyes) is sent to the left side of the brain, and information from the left visual field is sent to the right side of the brain." 

Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/

---
class: center, middle

.image-100[![](images/2b-wave.jpeg)]<br />
.image-100[![](images/2b-wavelengths-2.jpeg)]

???

The information to be RECORDED is light waves. Two physical characteristics of waves are AMPLITUDE and WAVELENGTH. The amplitude is measured from the peak to the trough and the length is the distance between two peaks. 

Wavelength is directly related to frequency, which refers to the number of waves that pass a given point at a particular time period, and is measured in terms of cycles per second or Hertz (Hz). Longer wavelengths of lower frequencies and shorter wavelengths have higher frequencies. 

Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/

---
class: center, middle

.image-100[![](images/2b-wavelengths.jpeg)] 

???

"The visible spectrum is the portion of the larger electromagnetic spectrum that we can see. ... The visible spectrum in humans is associated with wavelengths that range from 380 to 740 [nanometers] nm ... one billionth of a meter. ... Other species can see other portions ... For instance, honeybees can see light in the ultraviolet range... and some snakes can detect infrared radiation"
Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/

---
class: center, middle

.image-100[![](images/2b-visible light.jpeg)] 

???

"In humans, light **wavelength** is associated with perception of color. Within the visible spectrum, our experience of red is associated with longer wavelengths, greens are intermediate, and blues and violets are shorter in wavelength. ... The **amplitude** of light waves is associated with our experience of brightness or intensity of color, with larger amplitudes appearing brighter."

Source: https://courses.lumenlearning.com/wmopen-psychology/chapter/outcome-vision/

More on the brain side of visual processing: https://nba.uth.tmc.edu/neuroscience/s2/chapter15.html

---

.image-100[![](images/2b-info-to-V1.png)]

???

"The spatial relationships among the ganglion cells in the retina are maintained in their central targets as orderly representations or “maps” of visual space." https://www.ncbi.nlm.nih.gov/books/NBK10944/

the *measurable* result can be imagined in this way: here, a Vq neuron's response to this stimulus. Its receptive field was centered on a grey square, while the luminance—from light to dark—of the surrounding area was modulated. "The cell's response was synchronized to the surround modulation and correlated with the **perceived** lightness of the central patch, even though nothing changed within the receptive field." https://www.pnas.org/content/98/22/12340 

Apat from the many questions raised here, what we have is some kind of analog recording of the intensities of luminance by the neuron. This is what we're able to record at the physical level. 

Now of course, "Cognitive and perceptual states are held by many (Ayers
2019; Burge 2010; Burnston 2017; Carey 2009; Crane 2003;
Dretske 1981; Fodor 2007; Goodman 1976; Heck 2007;
Haugeland 1987; Jackendoff 1987; Peacocke 1986, 2019) to
be cast in different representational formats, namely, digital
or symbolic, and analog formats respectively.
Assuming this distinction, if one holds that cognition and
perception interact the problem immediately emerges as to
how this interaction could take place in view of the differing
representational formats." https://cogsci.mindmodeling.org/2020/papers/0799/0799.pdf

That question - whether one of computational implementation or otherwise - is the outstanding one at the bridge between neuroscience and cognitive science. 

But vision doesn't simply "measure" or "record" *what's out there*, of course. 












---
template: inverse

# Visual intelligence

---
# Visual .red[intelligence]

1. Light enters our eye and hits our retina.

2. Light that hits the retina from four miles away is the same as light that hits the retina from 4 feet away. There is no direct information about depth entering the eye. Sometimes the cognitive scientist will refer to the retina as if it gathers information in terms of two dimensions.

3. Our experience of seeing is in terms of three dimensions. .red[We see depth (even though our eyes don't)]

4. .red[We see objects (even though our eyes don't)]
???

Source: Reiss Trois Rivieres slides. 

Image source: https://en.wikipedia.org/wiki/Visual_system

---
# .red[Constructing] visual experience

Given any two-dimensional representation there is more than one way to extend it (consistently) into three dimensions. 

*That* the same information hitting our eyes can be *seen* in two different ways suggests a *constructive process* that other ways of thinking how vision works struggle with. 

???

Source: Reiss Trois Rivieres slides. 


---
class: center

.image-60[![](images/necker1.png)]

???

Consider the .red[Necker Cube]. We actually see more than one cube in the diagram...


---
class: center
.image-60[![](images/vi1-triangle constructed by the visual system.png)]

???

Now the Kanisza triangle. There is no triangle. We see a triangle.

---
class: center
.image-60[![](images/necker2.png)]

???

The Necker cube embedded in a Kanisza-type image. 

---
class: center, middle
.image-60[![](images/2b-bela-julesz.jpg)]

???

Random dot stereograms developed by Bela Julesz, Hungarian-American neuroscientist and experimental psychologist 

Floating triangle (I can't see it). (Source: http://dada.compart-bremen.de/item/artwork/739)



---
# Visual .red[grammar]

What we see is determined according to "principles" that parallel the "rules" of linguistic grammar..red[*]

The fact that different species see things differently reflects the fact that these principles must be internal to individuals, and .red[not just a reflection of the nature of the physical world]. 

The fact that you can assign a unique interpretation to an unbounded number of visual scenes is also evidence that our visual knowledge is grammar-like.

.footnote[.red[*] Quoting Hoffmann (2000), <i>Visual Intelligence</i>]

???

Donald D. Hoffman, a vision scientist studying consciousness and evolutionary psychology at UC Irvine. 

Based on Reiss quoting Hoffman

---
class: center
.image-100[![](images/vi2-humans and bees1.png)]

???

.image-100[![](images/vi2-humans and bees1-commentary.png)]

Humans and bees treat these as the same, for the purposes of orientiation/action planning 

Source: Reiss Trois Rivieres slides. 

---
class: center
.image-100[![](images/vi3-humans and bees2.png)]

???

.image-100[![](images/vi3-humans and bees2-commentary.png)]

Bees do not treat these as members of the same category as the previous set 

Source: Reiss Trois Rivieres slides. 



---
class: center
.image-60[![](images/vi4-an illusory triskaidecagon.png)]

???

We don't need to know the name of the thing, it's not like that - applies to arbitrary novel shapes 

(Apparently it's called a .red[triskaidecagon] - a polygon having thirteen sides and thirteen angles)


---
class: center
.image-60[![](images/vi5-unnamed form constructed by the visual system.png)]







---
# Contemporary vision science.red[*]

### .red[A critical component of vision is the creation of visual entities], representations of surfaces and objects that do not change the base data of the visual scene but change which parts we see as belonging together and how they are arrayed in depth.

.footnote[.red[*] From the 50th anniversary issue of <i>Vision Research</i>, Cavanagh (2011)]




---
# Contemporary vision science


.image-100[![](images/2b-cavanagh-1.png)]



???

"The descriptions of surfaces, objects, and events computed by mid- and high-level processes are not solely for consumption in the visual system but live at a level that is appropriate for passing on to other brain centers. Clearly, the description of visual scene cannot be sent in its entirety, like a picture or movie, to other centers as that would require that each of them have their own visual system to decode the description. Some very compressed, annotated, or labeled version must be constructed that can be passed on in a format and that other centers – memory, language, planning – can understand" 

"The nature of this high-level, visual description that can be exported to and understood by other centers is as yet, completely unknown. We can imagine that it might embody the content that we label as conscious vision"

Source: Cavanagh (2011). Cites Baars, 1988, 2002; Dehaene & Naccache, 2001; van der Velde, 2006.




